{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i-NOmBmvJJ06"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A2NAUtrEJNS3"
   },
   "outputs": [],
   "source": [
    "# define the autoencoder (with more layers this time)\n",
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self, input_size, first_hidden_layer_size, second_hidden_layer_size, latent_size):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Linear(input_size, first_hidden_layer_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(first_hidden_layer_size, second_hidden_layer_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(second_hidden_layer_size, latent_size),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(latent_size, second_hidden_layer_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(second_hidden_layer_size, first_hidden_layer_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(first_hidden_layer_size, input_size),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    \n",
    "    x = self.decoder(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JBa8QWb-JNVg"
   },
   "outputs": [],
   "source": [
    "# read in the unnormalized feature matrix\n",
    "data_np = np.loadtxt('feature_matrix_path.csv', delimiter=',') #TODO: change path\n",
    "data = data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.,   0.,   0., ...,   0.,   0.,  12.],\n",
       "       [ 10.,   3.,   0., ...,   1.,   0.,   9.],\n",
       "       [  8.,   0.,   0., ...,   1.,   1.,   5.],\n",
       "       ...,\n",
       "       [ 30.,   1.,   0., ...,   1.,   1.,  11.],\n",
       "       [618.,   1.,   3., ...,   1.,   0.,  21.],\n",
       "       [ 20.,   2.,   0., ...,   0.,   0.,  18.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTkmSFurJNXz",
    "outputId": "e8cd2488-909e-459a-e4e6-883c26b43c72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.47058824e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.41176471e-01],\n",
       "       [5.55555556e-02, 1.66666667e-02, 0.00000000e+00, ...,\n",
       "        5.55555556e-03, 0.00000000e+00, 5.00000000e-02],\n",
       "       [4.54545455e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        5.68181818e-03, 5.68181818e-03, 2.84090909e-02],\n",
       "       ...,\n",
       "       [3.12500000e-01, 1.04166667e-02, 0.00000000e+00, ...,\n",
       "        1.04166667e-02, 1.04166667e-02, 1.14583333e-01],\n",
       "       [3.63614968e-02, 5.88373735e-05, 1.76512120e-04, ...,\n",
       "        5.88373735e-05, 0.00000000e+00, 1.23558484e-03],\n",
       "       [1.35135135e-01, 1.35135135e-02, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.21621622e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize feature matrix by row (sample)\n",
    "max_values = data.max(axis=1)\n",
    "data = data / max_values[:, None]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=532446, out_features=1500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1500, out_features=300, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=300, out_features=1500, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1500, out_features=532446, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model we're using\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = data.shape[1]\n",
    "first_hidden_layer_size = 1500\n",
    "second_hidden_layer_size = 300\n",
    "latent_size = 100\n",
    "model = Autoencoder(input_size, first_hidden_layer_size, second_hidden_layer_size, latent_size)\n",
    "model.load_state_dict(torch.load('autoencoder_15_1000.pth')) #TODO: change path (if necessary)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683\n"
     ]
    }
   ],
   "source": [
    "# convert to tensor so it can be inputted\n",
    "data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "\n",
    "# create dataset\n",
    "dataset = TensorDataset(data, data)  # the first arg is the input, the second is the target. for autoencoder they're the same\n",
    "embedddings_dataloarder = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in embedddings_dataloarder:\n",
    "        inputs = inputs.to(device)\n",
    "        encoded_data = model.encoder(inputs)[0]\n",
    "        embeddings.append(encoded_data.cpu())\n",
    "\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame([tensor.tolist() for tensor in embeddings])\n",
    "embeddings_df.to_csv('embeddings_output_path.csv', index=False, header=[f\"Dim_{i+1}\" for i in range(embeddings_df.shape[1])]) #TODO: change path"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
