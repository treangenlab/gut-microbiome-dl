{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj_A8il7ICk9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class Autoencoder(nn.Module):\n",
        "#   def __init__(self, input_size, hidden_size, latent_size):\n",
        "#     super(Autoencoder, self).__init__()\n",
        "#     self.encoder = nn.Sequential(\n",
        "#       nn.Linear(input_size, hidden_size),\n",
        "#       nn.ReLU(), # should decide on the relu variant, but it's just basic relu rn as a placeholder\n",
        "#       nn.Linear(hidden_size, latent_size),\n",
        "#       nn.ReLU()\n",
        "#     )\n",
        "#     self.decoder = nn.Sequential(\n",
        "#       nn.Linear(latent_size, hidden_size),\n",
        "#       nn.ReLU(),\n",
        "#       nn.Linear(hidden_size, input_size),\n",
        "#       nn.ReLU()\n",
        "#     )\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     x = self.encoder(x)\n",
        "#     x = self.decoder(x)\n",
        "#     return x\n"
      ],
      "metadata": {
        "id": "llSq0ukLIET7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # define dimensions\n",
        "# input_size = 10000  # replace with correct number of features\n",
        "# hidden_size = 10\n",
        "# latent_size = 4\n",
        "\n",
        "# # make model, instance of autoencoder\n",
        "# model = Autoencoder(input_size, hidden_size, latent_size)\n",
        "\n",
        "# # binary cross entropy (since output is in [0, 1]) <-- nope because it isn't, whoops\n",
        "# loss_fn = nn.MSELoss()\n",
        "\n",
        "# # optimizer (using adam for rn just bc i've used it before). will probably have to change to (mini batch?) LBGFS when using GPUs for parallelizing. refer to felix's big autoencoder paper\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001) # how/where do i set batch size\n",
        "\n",
        "# # random data - replace with actual matrix\n",
        "# data = np.random.rand(1700, 10000)  # 100 samples, 50 features (corresponds to input_size)\n",
        "\n",
        "# # convert to tensor so it can be inputted\n",
        "# data = torch.tensor(data, dtype=torch.float)\n",
        "\n",
        "# # train model\n",
        "# num_epochs = 100\n",
        "# for epoch in range(num_epochs):\n",
        "#   # forward pass\n",
        "#   outputs = model(data)\n",
        "#   loss = loss_fn(outputs, data)\n",
        "\n",
        "#   # backprop\n",
        "#   optimizer.zero_grad()\n",
        "#   loss.backward()\n",
        "#   optimizer.step()\n",
        "\n",
        "#   # so we can see epochs and loss at each\n",
        "#   if (epoch+1) % 10 == 0:\n",
        "#     print('Epoch:', epoch+1, '/', num_epochs, ' Loss:', loss.item())\n",
        "\n",
        "# # try to reconstruct the first sample based on the model ^\n",
        "# sample_input = data[0].unsqueeze(0)\n",
        "# reconstructed = model(sample_input)\n",
        "# print(\"original:\")\n",
        "# print(sample_input)\n",
        "# print(\"reconstructed:\")\n",
        "# print(reconstructed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nsTkGr0IX1A",
        "outputId": "3184e8e8-41c1-4ced-d32c-f4efc917b9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 100  Loss: 0.2577957212924957\n",
            "Epoch: 20 / 100  Loss: 0.25031405687332153\n",
            "Epoch: 30 / 100  Loss: 0.2428545355796814\n",
            "Epoch: 40 / 100  Loss: 0.23592348396778107\n",
            "Epoch: 50 / 100  Loss: 0.2296619862318039\n",
            "Epoch: 60 / 100  Loss: 0.22411970794200897\n",
            "Epoch: 70 / 100  Loss: 0.2192796766757965\n",
            "Epoch: 80 / 100  Loss: 0.21508640050888062\n",
            "Epoch: 90 / 100  Loss: 0.21151889860630035\n",
            "Epoch: 100 / 100  Loss: 0.20851656794548035\n",
            "original:\n",
            "tensor([[0.8810, 0.6215, 0.5171,  ..., 0.9816, 0.2788, 0.5191]])\n",
            "reconstructed:\n",
            "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.5049, 0.0000, 0.4936]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_size):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "      nn.Linear(input_size, hidden_size),\n",
        "      nn.ReLU(), # should decide on the relu variant, but it's just basic relu rn as a placeholder\n",
        "      nn.Linear(hidden_size, latent_size),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "      nn.Linear(latent_size, hidden_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_size, input_size),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ad5LPVgsc8fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device) # to run on GPU on colab, go to runtime > change runtime type > T4 GPU\n",
        "\n",
        "# define dimensions\n",
        "input_size = 10000\n",
        "hidden_size = 10\n",
        "latent_size = 4\n",
        "\n",
        "# make model, instance of autoencoder\n",
        "model = Autoencoder(input_size, hidden_size, latent_size).to(device)\n",
        "\n",
        "# binary cross entropy (since output is in [0, 1])\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# optimizer\n",
        "# actually not going to change this to LBGFS because it takes more memory (stores the hess) and rn memory is more of an issue than speed I think\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # can tune lr, also not high priority. Should it be .01 instead of .001?\n",
        "\n",
        "# random data - replace with actual matrix\n",
        "data = np.random.rand(1700, 10000)\n",
        "\n",
        "# convert to tensor so it can be inputted\n",
        "data = torch.tensor(data, dtype=torch.float).to(device)\n",
        "\n",
        "# create dataset\n",
        "dataset = TensorDataset(data, data) # the first arg is the input, the second is the target. for autoencoder they're the same so it's just (data, data)\n",
        "\n",
        "# create dataloader\n",
        "batch_size = 64 # will probably be another thing to tune, but doubt it's high priority\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# train model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.0\n",
        "  for batch_data, _ in dataloader: # _ was for target but since it's the same thing might as well save mem\n",
        "    batch_data = batch_data.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(batch_data)\n",
        "    loss = loss_fn(outputs, batch_data)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # print epoch loss\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print('Epoch:', epoch+1, '/', num_epochs, ' Loss:', epoch_loss / len(dataloader))\n",
        "\n",
        "# try to reconstruct the first sample based on the model\n",
        "sample_input = data[0].unsqueeze(0).to(device)\n",
        "reconstructed = model(sample_input)\n",
        "print(\"original:\")\n",
        "print(sample_input)\n",
        "print(\"reconstructed:\")\n",
        "print(reconstructed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mZKtHn4hXrZ",
        "outputId": "cb852fb4-b460-4fdf-9a59-ce2a2ffd862c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch: 10 / 100  Loss: 0.19335379699865976\n",
            "Epoch: 20 / 100  Loss: 0.19242097878897632\n",
            "Epoch: 30 / 100  Loss: 0.19241185320748222\n",
            "Epoch: 40 / 100  Loss: 0.19242376972127845\n",
            "Epoch: 50 / 100  Loss: 0.19242376309854012\n",
            "Epoch: 60 / 100  Loss: 0.19243269717251812\n",
            "Epoch: 70 / 100  Loss: 0.19242406167365886\n",
            "Epoch: 80 / 100  Loss: 0.19243369444652839\n",
            "Epoch: 90 / 100  Loss: 0.1924355979318972\n",
            "Epoch: 100 / 100  Loss: 0.19243286108529126\n",
            "original:\n",
            "tensor([[0.5553, 0.4815, 0.3130,  ..., 0.7352, 0.1472, 0.3634]],\n",
            "       device='cuda:0')\n",
            "reconstructed:\n",
            "tensor([[0.5007, 0.0000, 0.0000,  ..., 0.4920, 0.5116, 0.4900]],\n",
            "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLBw7_1O9sYi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}